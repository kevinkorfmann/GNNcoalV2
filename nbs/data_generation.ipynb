{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8dbc7-854a-4f41-9bb8-5ab43856926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2dfad2-15ad-485d-be5a-769e3833c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "from scipy.interpolate import interp1d\n",
    "import tskit\n",
    "from tqdm import tqdm\n",
    "import msprime\n",
    "\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import networkx as nx\n",
    "import torch\n",
    "\n",
    "import random\n",
    "from scipy.special import beta\n",
    "import networkx as nx\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils.to_dense_adj import to_dense_adj\n",
    "from torch_geometric.utils.to_dense_batch import to_dense_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d626c-a8fc-4541-a5dd-e97d37e51d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Seed all random number generators.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # Ensure deterministic behavior (this can slow down training, so you might not always want it)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e091740b-1042-4aae-adba-2f1bf7998214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def sample_constant_population_size(n_min:int=10, n_max:int=100_000, num_time_windows=21):\n",
    "    return np.random.uniform(n_min, n_max, 1).tolist() * num_time_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be7405-9ef6-4aff-930d-3f54e1f8d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def sample_population_size(n_min:int=10, n_max:int=100_000, num_time_windows=21):\n",
    "    \n",
    "    \"\"\"Creates random demography. Function taken from: \n",
    "    https://gitlab.inria.fr/ml_genetics/public/dlpopsize_paper\n",
    "    \n",
    "    :param int n_min: Lower-bound of demography.\n",
    "    :param int n_max: Upper-bound of demography.\n",
    "    :param int num_time_windows: Number of population sizes in demography.\n",
    "    :return list: \n",
    "    \"\"\"\n",
    "    \n",
    "    n_min_log10 = np.log10(n_min)\n",
    "    n_max_log10 = np.log10(n_max)\n",
    "    population_size = [10 ** np.random.uniform(low=n_min_log10, high=n_max_log10)] \n",
    "    for j in range(num_time_windows - 1):\n",
    "        population_size.append(10 ** n_min_log10 - 1)\n",
    "        while population_size[-1] > 10 ** n_max_log10 or population_size[-1]  < 10 ** n_min_log10:\n",
    "            population_size[-1] = population_size[-2] * 10 ** np.random.uniform(-1, 1)\n",
    "            \n",
    "    return population_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70df1c-65f5-47dc-9874-9b4bf898be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_population_time(time_rate:float=0.06, tmax:int = 130_000,\n",
    "                        num_time_windows:int = 21\n",
    "                       ) -> np.array :\n",
    "    \"\"\"Creates population time points; used as time points to change\n",
    "    population size changes for simulation\n",
    "    \n",
    "    :return numpy.ndarray: time points of length num_time_windows\n",
    "    \"\"\"\n",
    "    \n",
    "    population_time = np.repeat([(np.exp(np.log(1 + time_rate * tmax) * i /\n",
    "                              (num_time_windows - 1)) - 1) / time_rate for i in\n",
    "                              range(num_time_windows)], 1, axis=0)\n",
    "    population_time[0] = 1\n",
    "    return population_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf0736-5f89-4575-a610-152cd4cda5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def simulate_scenario(population_size: Union[list, np.ndarray],\n",
    "                      population_time: Union[list, np.ndarray],\n",
    "                      mutation_rate: float,\n",
    "                      recombination_rate: float,\n",
    "                      segment_length: float,\n",
    "                      num_sample:int,\n",
    "                      num_replicates: int,\n",
    "                      seed: int = 69420,\n",
    "                      model = None,\n",
    "                     ):\n",
    "\n",
    "    \"\"\" Simulates tree sequence with msprime given population size changes at specific time-points.\n",
    "    Piece-wise constant simualtion of demography.\n",
    "    \n",
    "    :return: generator of tskit.trees.TreeSequence\n",
    "    \"\"\"\n",
    "\n",
    "    demography=msprime.Demography()\n",
    "    demography.add_population(initial_size=(population_size[0]))\n",
    "    for i, (time, size) in enumerate(zip(population_time, population_size)):\n",
    "        if i != 0:\n",
    "            demography.add_population_parameters_change(time=time, initial_size=size)\n",
    "\n",
    "    tss = msprime.sim_ancestry(samples=num_sample, recombination_rate=recombination_rate,\n",
    "                                          sequence_length=int(segment_length), demography=demography,\n",
    "                                          ploidy=1, model=model, num_replicates=num_replicates, random_seed=seed)\n",
    "\n",
    "    return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed761a0-a493-47b2-b5cd-f5bb31af2cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sample_parameters(num_time_windows = 60,\n",
    "                      n_min = 10_000,\n",
    "                      n_max = 10_000_000,\n",
    "                      recombination_rates = [1e-8, 1e-8],\n",
    "                      population_size= None,\n",
    "                      model = None,\n",
    "                      \n",
    "                      ) -> pd.DataFrame:\n",
    "    \n",
    "\n",
    "    parameter_names = [\"recombination_rate\"]\n",
    "    for i in range(num_time_windows): parameter_names.append(\"pop_size_\" + str(i))\n",
    "    parameter_names.append(\"model\")\n",
    "    parameters = []\n",
    "    recombination_rate = np.random.uniform(low=recombination_rates[0], high=recombination_rates[1])\n",
    "\n",
    "    if population_size is None:\n",
    "        population_size = sample_population_size(n_min=n_min, n_max=n_max, num_time_windows=num_time_windows)\n",
    "    \n",
    "    parameter = [recombination_rate]\n",
    "    for current_population_size in population_size: \n",
    "        parameter.append(current_population_size)\n",
    "    parameter.append(model)\n",
    "    parameters.append( parameter )\n",
    "    parameters = pd.DataFrame(parameters, columns=parameter_names)\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017a87c-640a-420d-8b51-71728a056dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def sample_population_size(n_min:int=10, n_max:int=100_000, num_time_windows=21):\n",
    "    \n",
    "    \"\"\"Creates random demography. Function taken from: \n",
    "    https://gitlab.inria.fr/ml_genetics/public/dlpopsize_paper\n",
    "    \n",
    "    :param int n_min: Lower-bound of demography.\n",
    "    :param int n_max: Upper-bound of demography.\n",
    "    :param int num_time_windows: Number of population sizes in demography.\n",
    "    :return list: \n",
    "    \"\"\"\n",
    "    \n",
    "    n_min_log10 = np.log10(n_min)\n",
    "    n_max_log10 = np.log10(n_max)\n",
    "    population_size = [10 ** np.random.uniform(low=n_min_log10, high=n_max_log10)] \n",
    "    for j in range(num_time_windows - 1):\n",
    "        population_size.append(10 ** n_min_log10 - 1)\n",
    "        while population_size[-1] > 10 ** n_max_log10 or population_size[-1]  < 10 ** n_min_log10:\n",
    "            population_size[-1] = population_size[-2] * 10 ** np.random.uniform(-1, 1)\n",
    "            \n",
    "    return population_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60efdb83-e128-4184-95d4-03382524ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sample_smooth_population_parameters():\n",
    "\n",
    "    upper_out_of_bound = lower_out_of_bound = True\n",
    "    while upper_out_of_bound or lower_out_of_bound:\n",
    "        steps = 18\n",
    "        x = np.log(get_population_time(time_rate=0.1, num_time_windows=steps, tmax=10_000_000).tolist())\n",
    "        y = np.log(sample_population_size(10_000, 10_000_000, steps))\n",
    "        xnew = np.linspace(x[0], x[-1], num=10000, endpoint=True)\n",
    "        f_cubic = interp1d(x, y, kind='cubic')\n",
    "        ynew = f_cubic(xnew)\n",
    "        upper_out_of_bound = np.sum(np.exp(ynew) > 10_000_000) > 0\n",
    "        lower_out_of_bound = np.sum(np.exp(ynew) < 10_000) > 0\n",
    "        x_sample = xnew[np.linspace(10, 9999, 60).astype(int)]\n",
    "        y_sample = ynew[np.linspace(10, 9999, 60).astype(int)]\n",
    "        population_time = np.exp(x_sample)\n",
    "        population_size = np.exp(y_sample)\n",
    "        \n",
    "    return population_time, population_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736f1a6-ba21-469b-9069-25b24d1b738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def simulate_tree_sequence(parameters: pd.DataFrame,\n",
    "                           population_time: list, \n",
    "                           segment_length = 1e6, \n",
    "                           num_sample = 10, \n",
    "                           num_replicates = 100,\n",
    "                           seed = 69420,\n",
    "                          ):\n",
    "    \n",
    "    tree_sequences = []\n",
    "    population_size = parameters.loc[\"pop_size_0\":\"pop_size_\" + str(len(population_time)-1)].tolist()\n",
    "    recombination_rate = parameters.loc[\"recombination_rate\"]\n",
    "    model = parameters.loc[\"model\"]\n",
    "    \n",
    "    if type(model) == np.float64:\n",
    "        model = msprime.BetaCoalescent(alpha=model)\n",
    "    else:\n",
    "        model = None\n",
    "        \n",
    "    tree_sequences = simulate_scenario(population_size=population_size,\n",
    "                    population_time=population_time,\n",
    "                    mutation_rate=0, # otherwise memory not sufficient\n",
    "                    recombination_rate=recombination_rate,\n",
    "                    segment_length=segment_length,\n",
    "                    num_sample=num_sample,\n",
    "                    num_replicates=num_replicates,\n",
    "                    seed=seed, model=model)\n",
    "        \n",
    "    tss = []\n",
    "    for ts in tree_sequences:\n",
    "        tss.append(ts)    \n",
    "        \n",
    "    return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52262cfc-1f81-4198-b20b-5fc1b6a6b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_sample(nth_scenario, num_sim_trees, alpha):\n",
    "    \n",
    "    sequence_length = 1_000_000\n",
    "    #alpha = np.round(np.random.uniform(1.01, 1.99), 2)\n",
    "    population_time , population_size = sample_smooth_population_parameters()\n",
    "   \n",
    "    parameter_set = sample_parameters(\n",
    "       num_time_windows=60,\n",
    "       n_min = 10_000,\n",
    "       n_max = 10_000_000,\n",
    "       recombination_rates=[1e-8, 1e-8],\n",
    "       population_size=population_size,\n",
    "       model=alpha   \n",
    "    )\n",
    "\n",
    "    num_replicates = 1\n",
    "    ts = simulate_tree_sequence(\n",
    "        parameter_set.iloc[0],\n",
    "        population_time=population_time,\n",
    "        segment_length=sequence_length,\n",
    "        num_replicates=num_replicates, \n",
    "        seed=nth_scenario+1, #+1*1000,\n",
    "    )[0]\n",
    "\n",
    "    while ts.num_trees < num_sim_trees:\n",
    "        sequence_length = sequence_length * 1.2\n",
    "        ts = simulate_tree_sequence(\n",
    "            parameter_set.iloc[0],\n",
    "            population_time=population_time,\n",
    "            segment_length=sequence_length,\n",
    "            num_replicates=num_replicates, \n",
    "            seed=nth_scenario+1,\n",
    "        )[0]\n",
    "\n",
    "    return ts, population_size, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a3856-714f-4d9a-bdbc-d51d80abe475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# def alternative_coalescent_mask(ts, population_time, x_times_std=2, n_trees=500):\n",
    "    \n",
    "#     trees = ts.aslist()[0:n_trees]\n",
    "#     nodes_n_trees = []\n",
    "#     for tree in trees:\n",
    "#         nodes_n_trees += list(tree.nodes())\n",
    "    \n",
    "#     node_times = [ts.get_time(node.id) for node in ts.nodes() if node.id >= ts.num_samples and node.id in nodes_n_trees]\n",
    "    \n",
    "#     log_node_times = np.log(node_times)\n",
    "#     mean = log_node_times.mean()\n",
    "#     std = log_node_times.std()\n",
    "#     lowerbound = np.exp(mean-x_times_std*std)\n",
    "#     upperbound = np.exp(mean+x_times_std*std)\n",
    "#     mask1 = population_time > lowerbound\n",
    "#     mask2 = population_time < upperbound\n",
    "#     mask = np.logical_and(mask1, mask2)\n",
    "#     return mask\n",
    "\n",
    "\n",
    "def alternative_coalescent_mask(ts, population_time, threshold=10, num_sim_trees=500, nth_tree=1):\n",
    "    \n",
    "    #trees = ts.aslist()[0:num_sim_trees:nth_tree]\n",
    "    nodes_n_trees = []\n",
    "    #for tree in trees: \n",
    "    #    nodes_n_trees += list(tree.nodes())\n",
    "\n",
    "    for i, tree in enumerate(ts.trees()):\n",
    "        if i < num_sim_trees and i % nth_tree == 0:\n",
    "            nodes_n_trees += list(tree.nodes())\n",
    "    \n",
    "        \n",
    "    node_times = [ts.get_time(node.id) for node in ts.nodes() if node.id >= ts.num_samples and node.id in nodes_n_trees]\n",
    "    hist, bin_edges = np.histogram(node_times, bins=population_time)\n",
    "\n",
    "    mask = np.zeros(60) != 0\n",
    "    mask[1:] = hist > threshold\n",
    "    \n",
    "    start = np.argwhere(mask == 1)[0]\n",
    "    end = np.argwhere(mask == 1)[-1]\n",
    "    mask[int(start):int(end+1)] = True\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe44b91c-6748-4b92-b1ae-6f0f70b79f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f277bc5e-2d34-4219-979b-8ef6381d6114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def ts_to_data_objects(ts, num_sim_trees=500, nth_tree=1, num_embedding=60, y=None):\n",
    "    max_num_nodes = 2 * ts.num_samples - 1\n",
    "    data_objects = []\n",
    "    \n",
    "    #trees = ts.aslist()[0:num_sim_trees:nth_tree]\n",
    "    for i, tree in enumerate(ts.trees()):\n",
    "        if i < num_sim_trees and i % nth_tree == 0:\n",
    "            \n",
    "            data = from_networkx(nx.Graph(tree.as_dict_of_dicts()))\n",
    "            data.edge_weight = data.branch_length \n",
    "            data.branch_length  = None\n",
    "            data.x = torch.eye(max_num_nodes, num_embedding)\n",
    "            data.x[data.num_nodes:] = torch.zeros(num_embedding)\n",
    "            data.num_nodes = max_num_nodes\n",
    "            data.y = y\n",
    "            data_objects.append(data)\n",
    "    return data_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba8078-668a-47ad-924f-155e25d07b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def calculate_beta_coal_ne_estimate(theta, sample_size, L, alpha, mu_real):\n",
    "    mu_estimated = theta / ((2*np.sum(1/np.array(range(1, sample_size)))) * L)\n",
    "    m = 1 + (1/((2**(alpha-1))*(alpha-1)))\n",
    "    scale = (m**alpha)/(alpha * beta(2-alpha,alpha))\n",
    "    Ne = (((mu_estimated/mu_real)/scale)**(1/(alpha-1)))\n",
    "    return Ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d72b1-ff0c-4b23-b238-c0d11a2d98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def generate_batch(\n",
    "    seed, alpha, batch_size, num_trees, num_sim_trees, nth_tree=1, scaling=\"log\", mutation_rate = 4e-8):\n",
    "\n",
    "    tss, demographies, alphas = zip(*[generate_sample(seed+i, num_sim_trees, alpha) for i in range(batch_size)])\n",
    "    demographies = np.array(demographies)\n",
    "\n",
    "\n",
    "    # based on num_sim_trees\n",
    "    tss = [msprime.mutate(ts, rate=mutation_rate) for ts in tss]\n",
    "    ne_norm_factors = [calculate_beta_coal_ne_estimate(ts.num_mutations,\n",
    "                                                     ts.sample_size, ts.sequence_length,\n",
    "                                                      alphas[i], mutation_rate) for i, ts in enumerate(tss)]\n",
    "    #ne_norm_factors = demographies.mean(1)\n",
    "        \n",
    "    population_time, _ = sample_smooth_population_parameters()\n",
    "    masks = [alternative_coalescent_mask(ts, population_time, num_sim_trees=num_sim_trees, threshold=10, nth_tree=nth_tree) for ts in tss]\n",
    "    \n",
    "    data_objects = []\n",
    "    for i, ts in enumerate(tss):\n",
    "        ne_norm_factor = ne_norm_factors[i]\n",
    "        ts_data_objects = ts_to_data_objects(ts, num_sim_trees=num_sim_trees,nth_tree=nth_tree, num_embedding=60)\n",
    "\n",
    "        \n",
    "        if scaling==\"log\": demographies[i] = np.log(demographies[i])\n",
    "        if scaling==\"log_ne\": demographies[i] = np.log(demographies[i] / ne_norm_factor)\n",
    "        if scaling==\"ne\": demographies[i] = demographies[i] / ne_norm_factor\n",
    "\n",
    "        \n",
    "        for data_object in ts_data_objects: \n",
    "            if scaling==\"log\": data_object.edge_weight = np.log(data_object.edge_weight)\n",
    "            if scaling==\"log_ne\": data_object.edge_weight = np.log(data_object.edge_weight  / ne_norm_factor)\n",
    "            if scaling==\"ne\": data_object.edge_weight = data_object.edge_weight  / ne_norm_factor\n",
    "                \n",
    "        data_objects += ts_data_objects    \n",
    "    \n",
    "    dl = DataLoader(data_objects, batch_size=num_trees*batch_size)\n",
    "\n",
    "    \n",
    "    batch = next(iter(dl))\n",
    "    adj_batch = to_dense_adj(batch.edge_index, batch=batch.batch,\n",
    "                        edge_attr=batch.edge_weight, max_num_nodes=None)\n",
    "    \n",
    "    x_batch, _ = to_dense_batch(batch.x, batch.batch)\n",
    "\n",
    "    masks_batch = torch.Tensor(np.array(masks))\n",
    "    alpha_batch = torch.Tensor(alphas)\n",
    "    demography_batch = torch.Tensor(demographies)\n",
    "    ne_norm_factors = torch.Tensor(ne_norm_factors)\n",
    "    \n",
    "    return x_batch, adj_batch, masks_batch, demography_batch, alpha_batch, ne_norm_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9a351-4adf-401f-8b75-b55f2a90a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def continously_add_batch_to_queue(\n",
    "    data_queue,\n",
    "    process_id,\n",
    "    num_processes,\n",
    "    seed_start_value,\n",
    "    num_trees = 1000,\n",
    "    num_sim_trees = 1000,\n",
    "    nth_tree = 1,\n",
    "    batch_size = 4,\n",
    "    scaling=\"log\",\n",
    "    mutation_rate = 4e-8\n",
    "):\n",
    "    \n",
    "    while True:\n",
    "        seed_value = process_id + seed_start_value\n",
    "        device = None\n",
    "        alpha = np.round(np.random.uniform(1.01, 1.99), 2)\n",
    "        try:\n",
    "            x_batch, adj_batch, masks_batch, demography_batch, alpha_batch, ne_norm_factors = generate_batch(\n",
    "                seed_value, alpha, batch_size=batch_size, num_trees=num_trees,num_sim_trees=num_sim_trees,\n",
    "                nth_tree=nth_tree, scaling=scaling, mutation_rate=mutation_rate)\n",
    "            data_point = [x_batch, adj_batch, masks_batch, demography_batch, alpha_batch]\n",
    "            data_queue.put(data_point)\n",
    "            seed_value += num_processes\n",
    "        except Exception as e:\n",
    "            print(e, seed_value, alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc88cda-d90c-43b7-9305-0913a3ea3c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_next_batch(data_queue): return data_queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a24a9-975d-4867-9570-fc59c746e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(0x1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8599391-6f95-4226-866d-9c17bfa2422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tss, demographies, alphas = [], [], []\n",
    "# for i in range(1):\n",
    "#     ts, demography, alpha = generate_sample(i)\n",
    "#     tss.append(ts)\n",
    "#     demographies.append(demography)\n",
    "#     alphas.append(alpha)\n",
    "# print(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c48123-e5cf-4959-98db-ce30b65a7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#population_time, _ = sample_smooth_population_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c4574-a57d-4a1c-84ed-eb8ccc28413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative_coalescent_mask(ts, population_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43c3a3-34aa-46ba-a021-9036dfe88936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
